{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "248dc7f9-2ea4-4d20-83f3-8851e8a99d62",
   "metadata": {},
   "source": [
    "## Important libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c1df3ed8-b07e-47df-923d-ac10a223ac09",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import imutils\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import classification_report\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e772cbc5-cb1b-4050-b023-5359b9d4fe7e",
   "metadata": {},
   "source": [
    "## import of dataset and labelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "df033f8e-7952-437b-a63b-9ae639a9c4bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of images with masks: 3724\n",
      "Number of images without masks: 3828\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Folder paths for images with masks and without masks\n",
    "mask_folder = r'C:\\Users\\DELL\\Face mask detection\\with_mask'\n",
    "without_mask_folder = r'C:\\Users\\DELL\\Face mask detection\\without_mask'\n",
    "\n",
    "# Initialize empty lists to store image data and labels\n",
    "images = []\n",
    "labels = []\n",
    "\n",
    "# Import images with masks\n",
    "for filename in os.listdir(mask_folder):\n",
    "    if filename.endswith('.jpg') or filename.endswith('.png'):\n",
    "        img_path = os.path.join(mask_folder, filename)\n",
    "        try:\n",
    "            img = cv2.imread(img_path)\n",
    "            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)  # Convert BGR to RGB\n",
    "            img = cv2.resize(img, (224, 224))  # Resize the image to a fixed size\n",
    "            images.append(img)\n",
    "            labels.append(1)  # 1 for images with masks\n",
    "        except Exception as e:\n",
    "            print(f\"Error occurred while processing {img_path}: {e}\")\n",
    "\n",
    "# Import images without masks\n",
    "for filename in os.listdir(without_mask_folder):\n",
    "    if filename.endswith('.jpg') or filename.endswith('.png'):\n",
    "        img_path = os.path.join(without_mask_folder, filename)\n",
    "        try:\n",
    "            img = cv2.imread(img_path)\n",
    "            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)  # Convert BGR to RGB\n",
    "            img = cv2.resize(img, (224, 224))  # Resize the image to a fixed size\n",
    "            images.append(img)\n",
    "            labels.append(0)  # 0 for images without masks\n",
    "        except Exception as e:\n",
    "            print(f\"Error occurred while processing {img_path}: {e}\")\n",
    "\n",
    "# Convert the lists to NumPy arrays for further processing\n",
    "images = np.array(images, dtype=object)  # Specify dtype=object to handle varying image dimensions\n",
    "labels = np.array(labels)\n",
    "\n",
    "# Print the number of imported images\n",
    "print(\"Number of images with masks:\", np.sum(labels == 1))\n",
    "print(\"Number of images without masks:\", np.sum(labels == 0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb84edff-21e8-4324-a67e-361826ba7786",
   "metadata": {},
   "source": [
    "## Splitting in test train set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "75443c1f-b419-4df6-9498-cf499a2bd7e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples in training set: 6041\n",
      "Number of samples in test set: 1511\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "# Perform train-test split\n",
    "test_size = 0.2  # Define the ratio of the test set\n",
    "random_state = 42  # Set the random state for reproducibility\n",
    "X_train, X_test, y_train, y_test = train_test_split(images, labels, test_size=test_size, random_state=random_state)\n",
    "\n",
    "# Print the number of samples in each set\n",
    "print(\"Number of samples in training set:\", len(X_train))\n",
    "print(\"Number of samples in test set:\", len(X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f85d336-b255-485e-be33-32f194e370c7",
   "metadata": {},
   "source": [
    "## Training using CNN Ml model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8250d70d-265e-4223-b3fc-495464186722",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "# Folder paths for images with masks and without masks\n",
    "mask_folder = r'C:\\Users\\DELL\\Face mask detection\\with_mask'\n",
    "without_mask_folder = r'C:\\Users\\DELL\\Face mask detection\\without_mask'\n",
    "\n",
    "# Initialize empty lists to store preprocessed image data and labels\n",
    "preprocessed_images = []\n",
    "labels = []\n",
    "\n",
    "# Preprocessing parameters\n",
    "image_size = (224, 224)  # Target image size for resizing\n",
    "mean = (0, 0, 0)  # Mean values for image normalization\n",
    "std = (1, 1, 1)  # Standard deviation values for image normalization\n",
    "\n",
    "# Import images with masks\n",
    "for filename in os.listdir(mask_folder):\n",
    "    if filename.endswith('.jpg') or filename.endswith('.png'):\n",
    "        img_path = os.path.join(mask_folder, filename)\n",
    "        try:\n",
    "            img = cv2.imread(img_path)\n",
    "            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)  # Convert BGR to RGB\n",
    "            img = cv2.resize(img, image_size)  # Resize the image to the target size\n",
    "            img = img.astype(np.float32)  # Convert image to float32 data type\n",
    "            img = (img - mean) / std  # Normalize the image\n",
    "            preprocessed_images.append(img)\n",
    "            labels.append(1)  # 1 for images with masks\n",
    "        except Exception as e:\n",
    "            print(f\"Error occurred while processing {img_path}: {e}\")\n",
    "\n",
    "# Import images without masks\n",
    "for filename in os.listdir(without_mask_folder):\n",
    "    if filename.endswith('.jpg') or filename.endswith('.png'):\n",
    "        img_path = os.path.join(without_mask_folder, filename)\n",
    "        try:\n",
    "            img = cv2.imread(img_path)\n",
    "            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)  # Convert BGR to RGB\n",
    "            img = cv2.resize(img, image_size)  # Resize the image to the target size\n",
    "            img = img.astype(np.float32)  # Convert image to float32 data type\n",
    "            img = (img - mean) / std  # Normalize the image\n",
    "            preprocessed_images.append(img)\n",
    "            labels.append(0)  # 0 for images without masks\n",
    "        except Exception as e:\n",
    "            print(f\"Error occurred while processing {img_path}: {e}\")\n",
    "\n",
    "# Convert the lists to NumPy arrays for further processing\n",
    "preprocessed_images = np.array(preprocessed_images)\n",
    "labels = np.array(labels)\n",
    "\n",
    "# Perform train-test split\n",
    "test_size = 0.2  # Define the ratio of the test set\n",
    "random_state = 42  # Set the random state for reproducibility\n",
    "X_train, X_test, y_train, y_test = train_test_split(preprocessed_images, labels, test_size=test_size, random_state=random_state)\n",
    "\n",
    "# Define the CNN model architecture\n",
    "model = keras.Sequential([\n",
    "    layers.Conv2D(32, (3, 3), activation='relu', input_shape=(image_size[0], image_size[1], 3)),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Conv2D(128, (3, 3), activation='relu'),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(64, activation='relu'),\n",
    "    layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "batch_size = 16\n",
    "epochs = 10\n",
    "model.fit(X_train, y_train, batch_size=batch_size, epochs=epochs, validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91765864-0a48-4294-b380-de283795418b",
   "metadata": {},
   "source": [
    "## Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edd33be4-2b0a-46c9-ac74-8c73a4da376a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model on the test set\n",
    "test_loss, test_accuracy = model.evaluate(X_test, y_test, verbose=2)\n",
    "print(\"Test Loss:\", test_loss)\n",
    "print(\"Test Accuracy:\", test_accuracy)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred_classes = np.round(y_pred).flatten()\n",
    "\n",
    "# Compute evaluation metrics\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred_classes))\n",
    "\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred_classes))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34485c4b-64bb-404b-b301-13058eeb704f",
   "metadata": {},
   "source": [
    "## use camera to implement model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5de4fb88-2631-4200-84bf-8be0aac26617",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from tensorflow import keras\n",
    "\n",
    "# Load the trained model\n",
    "model = keras.models.load_model('path/to/model.h5')\n",
    "\n",
    "# Define class labels\n",
    "class_labels = ['Without Mask', 'With Mask']\n",
    "\n",
    "# Define a function to preprocess the frame\n",
    "def preprocess_frame(frame):\n",
    "    # Preprocess the frame (resize, normalize, etc.)\n",
    "    preprocessed_frame = cv2.resize(frame, (224, 224))\n",
    "    preprocessed_frame = preprocessed_frame.astype(np.float32)\n",
    "    preprocessed_frame = (preprocessed_frame - (0, 0, 0)) / (1, 1, 1)  # Normalize based on your preprocessing parameters\n",
    "    preprocessed_frame = np.expand_dims(preprocessed_frame, axis=0)\n",
    "    return preprocessed_frame\n",
    "\n",
    "# Open the video capture\n",
    "cap = cv2.VideoCapture(0)  # Use 0 for the default camera or provide the appropriate index for other cameras\n",
    "\n",
    "while True:\n",
    "    # Read a frame from the video capture\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # Preprocess the frame\n",
    "    preprocessed_frame = preprocess_frame(frame)\n",
    "\n",
    "    # Perform inference\n",
    "    prediction = model.predict(preprocessed_frame)\n",
    "    predicted_class = int(np.round(prediction[0]))\n",
    "\n",
    "    # Get the predicted class label\n",
    "    class_label = class_labels[predicted_class]\n",
    "\n",
    "    # Draw the bounding box and class label on the frame\n",
    "    cv2.putText(frame, class_label, (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 255, 0), 2)\n",
    "    cv2.imshow('Face Mask Detection', frame)\n",
    "\n",
    "    # Break the loop if 'q' is pressed\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Release the video capture and close the OpenCV windows\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
